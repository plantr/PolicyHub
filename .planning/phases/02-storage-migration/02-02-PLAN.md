---
phase: 02-storage-migration
plan: 02
type: execute
wave: 2
depends_on:
  - 02-01
files_modified:
  - server/routes.ts
  - server/s3.ts
  - server/lib/supabase-admin.ts
  - client/src/lib/storage.ts
autonomous: true
requirements:
  - STOR-05
  - STOR-06

must_haves:
  truths:
    - "Upload routes return signed upload URLs instead of buffering files through the server"
    - "Download route returns a signed URL instead of streaming the file from local disk"
    - "PDF-to-markdown route fetches the PDF from Supabase Storage via signed URL instead of local filesystem"
    - "Delete route removes the file from Supabase Storage instead of local filesystem"
    - "Creating a new business unit also provisions a Supabase Storage bucket for it"
    - "Client-side TUS upload utility can upload files of any size using the resumable protocol"
    - "File type and size validation occurs before upload URL generation with clear error messages"
    - "A refreshSignedUrl function exists in client storage module enabling auto-refresh on signed URL expiry (Phase 4 wires into UI)"
  artifacts:
    - path: "server/routes.ts"
      provides: "Updated routes using Supabase Storage signed URLs for upload, download, delete, and pdf-to-markdown"
      contains: "storage-supabase"
    - path: "server/s3.ts"
      provides: "Deprecated — file gutted with re-exports pointing to storage-supabase.ts or removed entirely"
    - path: "client/src/lib/storage.ts"
      provides: "Client-side TUS upload utility with progress callback and file validation"
      exports: ["uploadFileToStorage", "validateFile", "refreshSignedUrl", "ACCEPTED_FILE_EXTENSIONS"]
  key_links:
    - from: "server/routes.ts"
      to: "server/storage-supabase.ts"
      via: "imports storage functions for all file operations"
      pattern: "import.*from.*storage-supabase"
    - from: "server/routes.ts"
      to: "server/storage-supabase.ts"
      via: "createBucketForBusinessUnit called in BU creation route"
      pattern: "createBucketForBusinessUnit"
    - from: "client/src/lib/storage.ts"
      to: "tus-js-client"
      via: "TUS resumable upload protocol for all file sizes"
      pattern: "import.*tus.*from.*tus-js-client"
---

<objective>
Replace all S3/local filesystem file operations in routes.ts with Supabase Storage equivalents, add bucket provisioning to BU creation, and create the client-side TUS upload utility.

Purpose: Completes the storage migration by wiring up the storage-supabase module (from Plan 02-01) into all existing routes, and providing the client-side upload capability that the Phase 4 UI will consume.
Output: Updated routes.ts, deprecated s3.ts, new client/src/lib/storage.ts.
</objective>

<execution_context>
@/Users/robert.plant/.claude/get-shit-done/workflows/execute-plan.md
@/Users/robert.plant/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-storage-migration/02-RESEARCH.md
@.planning/phases/02-storage-migration/02-01-SUMMARY.md
@server/routes.ts
@server/s3.ts
@server/storage-supabase.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace S3 routes with Supabase Storage signed URL routes</name>
  <files>
    server/routes.ts
    server/s3.ts
  </files>
  <action>
    **Step 1: Update imports in routes.ts**

    Remove the old s3 import:
    ```typescript
    // DELETE THIS LINE:
    import { generateS3Key, uploadToS3, getLocalFilePath, deleteFromS3 } from "./s3";
    ```

    Add new imports:
    ```typescript
    import {
      bucketName, storagePath, resolveFilename,
      createSignedUploadUrl, createSignedDownloadUrl,
      deleteStorageObject, createBucketForBusinessUnit,
      validateFileType, validateFileSize, ALLOWED_MIME_TYPES
    } from "./storage-supabase";
    import { supabaseAdmin } from "./lib/supabase-admin";
    ```

    NOTE: `supabaseAdmin` is needed by Step 8 for direct buffer uploads in legacy inline-upload routes.

    **Step 2: Update multer config**

    Change the multer `fileFilter` to accept all ALLOWED_MIME_TYPES (not just PDF). Update `limits.fileSize` to 10 MB (10485760). This multer config is still needed for the legacy inline-upload routes (document create + version create that embed a file in the multipart body). These will be phased out in Phase 4 when the client switches to signed URL upload, but must continue working during transition.

    ```typescript
    const upload = multer({
      storage: multer.memoryStorage(),
      limits: { fileSize: 10 * 1024 * 1024 }, // 10 MB
      fileFilter: (_req, file, cb) => {
        if (ALLOWED_MIME_TYPES.includes(file.mimetype)) {
          cb(null, true);
        } else {
          cb(new Error(`Unsupported file type: ${file.mimetype}. Accepted: PDF, Word, Excel, PowerPoint, PNG, JPEG`));
        }
      },
    });
    ```

    **Step 3: Add new signed upload URL endpoint**

    Add a NEW route that generates a signed upload URL. This is the Phase 2 upload flow — client calls this to get a URL, then uploads directly to Supabase Storage via TUS.

    ```
    POST /api/document-versions/:id/upload-url
    ```

    Body: `{ fileName: string, mimeType: string, fileSize: number }`

    Logic:
    1. Validate mimeType with `validateFileType()` — return 400 with message if invalid
    2. Validate fileSize with `validateFileSize()` — return 400 with message if invalid
    3. Look up the document version by ID to get `documentId`
    4. Look up the document to get `businessUnitId` — return 400 if document has no BU
    5. Call `resolveFilename(buId, docId, versionId, fileName)` to handle duplicates
    6. Call `storagePath(docId, versionId, resolvedFileName)` to build the object path
    7. Call `createSignedUploadUrl(buId, objectPath)` to get `{signedUrl, token, path}`
    8. Return JSON: `{ signedUrl, token, path, bucketId: bucketName(buId) }`

    **Step 4: Add upload confirmation endpoint**

    ```
    POST /api/document-versions/:id/upload-confirm
    ```

    Body: `{ storagePath: string, fileName: string, fileSize: number }`

    Logic:
    1. Look up the document version
    2. If version already has a pdfS3Key, delete the old file from storage using `deleteStorageObject(buId, oldPath)`
    3. Call `storage.updateDocumentVersionPdf(versionId, storagePath, fileName, fileSize)` to save the new path in DB
    4. Create audit log entry for pdf_uploaded
    5. Return the updated version

    **Step 5: Replace download route**

    Replace the existing `GET /api/document-versions/:id/pdf/download` route:

    OLD behavior: reads file from local disk via `getLocalFilePath()` and streams it
    NEW behavior: generates a signed download URL and returns it as JSON

    ```
    GET /api/document-versions/:id/pdf/download
    ```

    Query params: `?mode=download` (optional — default is inline preview)

    Logic:
    1. Look up version, get document to find businessUnitId
    2. If `mode=download`: call `createSignedDownloadUrl(buId, version.pdfS3Key, version.pdfFileName)` (forces Content-Disposition: attachment)
    3. Otherwise: call `createSignedDownloadUrl(buId, version.pdfS3Key)` (inline preview)
    4. Return JSON: `{ url: signedUrl, expiresIn: 3600 }`

    **NOTE:** This is a breaking change for the frontend (was streaming file, now returns JSON with URL). Phase 4 will update the client. For backward compatibility during transition, check the `Accept` header: if `application/json` → return JSON with URL; if not → redirect to the signed URL (302 redirect so existing `<a>` links and `window.open()` still work).

    **Step 6: Replace delete route**

    Update `DELETE /api/document-versions/:id/pdf`:
    - Replace `deleteFromS3(version.pdfS3Key)` with:
      1. Look up document to get businessUnitId
      2. Call `deleteStorageObject(buId, version.pdfS3Key)`
    - Rest of logic (update DB, audit log) stays the same

    **Step 7: Replace pdf-to-markdown route**

    Update `GET /api/document-versions/:id/pdf/to-markdown`:
    - Replace local file read with Supabase Storage fetch:
      1. Look up document to get businessUnitId
      2. Generate a short-lived signed URL: `createSignedDownloadUrl(buId, version.pdfS3Key)`
      3. Fetch the PDF: `const response = await fetch(signedUrl)` then `const buffer = Buffer.from(await response.arrayBuffer())`
      4. Pass buffer to pdfjs-dist as before
    - Remove the `fs` import (no longer reading from local filesystem)

    **Step 8: Update existing inline upload routes (document create + version create)**

    The existing `POST /api/documents/create` and `POST /api/document-versions/create` routes use multer to buffer the file. Update the S3 calls within these routes:

    For each route that has `if (req.file) { ... }`:
    1. Look up businessUnitId from the document
    2. Replace `generateS3Key(...)` with `storagePath(docId, versionId, req.file.originalname)` (use resolveFilename first for duplicate handling)
    3. Replace `uploadToS3(key, buffer, mimetype)` with: generate signed upload URL, then use `supabaseAdmin.storage.from(bucket).upload(path, buffer, { contentType })` — NOTE: since this is server-side with the file already in memory, use the direct `upload()` method via service-role client (no TUS needed for server-side buffer upload). Import `supabaseAdmin` from `./lib/supabase-admin`.
    4. Replace the s3Key in `updateDocumentVersionPdf()` with the new storage path

    **Step 9: Add bucket provisioning to BU creation route**

    In the `POST /api/business-units/create` handler (around line 46-58):
    - After `const bu = await storage.createBusinessUnit(input);`
    - Add: `await createBucketForBusinessUnit(bu.id);`
    - Wrap in try/catch — log warning on failure but don't fail the BU creation (bucket can be created manually)

    **Step 10: Gut server/s3.ts**

    Replace the entire contents of `server/s3.ts` with a deprecation notice and no exports:
    ```typescript
    // DEPRECATED: This module has been replaced by storage-supabase.ts
    // All S3/local file operations now use Supabase Storage via signed URLs.
    // This file is retained temporarily for reference during Phase 4 cleanup.
    //
    // See: server/storage-supabase.ts for the replacement module.
    ```

    This prevents accidental import of old functions. Phase 4 (CLNP-03) will delete this file entirely.
  </action>
  <verify>
    - `routes.ts` no longer imports from `./s3`
    - `routes.ts` imports from `./storage-supabase`
    - New endpoint `POST /api/document-versions/:id/upload-url` exists and returns JSON with signedUrl, token, path, bucketId
    - New endpoint `POST /api/document-versions/:id/upload-confirm` exists
    - Download route returns JSON `{ url, expiresIn }` or 302 redirect
    - Delete route calls `deleteStorageObject` instead of `deleteFromS3`
    - pdf-to-markdown uses `fetch(signedUrl)` instead of `fs.readFile(localPath)`
    - BU creation route calls `createBucketForBusinessUnit`
    - `server/s3.ts` contains only the deprecation comment (no function exports)
    - TypeScript compiles without errors: `npx tsc --noEmit`
  </verify>
  <done>
    All 5 upload locations, 1 download route, 1 delete route, and 1 pdf-to-markdown route in routes.ts use Supabase Storage via storage-supabase.ts. New signed-URL upload flow (upload-url + upload-confirm endpoints) is ready for client consumption. BU creation provisions a storage bucket. s3.ts is gutted. No references to generateS3Key, uploadToS3, getLocalFilePath, or deleteFromS3 remain in active code.
  </done>
</task>

<task type="auto">
  <name>Task 2: Install tus-js-client and create client-side storage utility</name>
  <files>client/src/lib/storage.ts</files>
  <action>
    **Step 1: Install tus-js-client**

    ```bash
    npm install tus-js-client
    ```

    **Step 2: Create client/src/lib/storage.ts**

    This is the client-side upload utility that Phase 4 UI components will consume. It provides the TUS upload function and file validation helpers.

    **Constants (exported):**
    - `ACCEPTED_FILE_EXTENSIONS`: `['.pdf', '.docx', '.xlsx', '.pptx', '.png', '.jpg', '.jpeg']`
    - `ACCEPTED_MIME_TYPES`: same 6 MIME types as server-side
    - `MAX_FILE_SIZE_BYTES`: 10485760 (10 MB)
    - `MAX_FILE_SIZE_DISPLAY`: `"10 MB"`
    - `TUS_CHUNK_SIZE`: `6 * 1024 * 1024` (6 MB — required by Supabase)

    **Types (exported):**
    ```typescript
    interface UploadOptions {
      file: File;
      signedUrl: string;       // from /api/document-versions/:id/upload-url
      token: string;           // from createSignedUploadUrl
      bucketId: string;        // e.g. "bu-42"
      objectPath: string;      // e.g. "101/202/abc12345_report.pdf"
      onProgress?: (percent: number) => void;  // 0-100
      onError?: (error: Error) => void;
    }

    interface FileValidationResult {
      valid: boolean;
      errors: string[];  // empty if valid, descriptive messages if not
    }
    ```

    **Functions (exported):**

    1. `validateFile(file: File): FileValidationResult`
       - Check file.size <= MAX_FILE_SIZE_BYTES — error: "File too large: {sizeInMB} MB. Maximum: 10 MB"
       - Check file.type is in ACCEPTED_MIME_TYPES — error: "Unsupported file type: {file.type}. Accepted: PDF, Word (.docx), Excel (.xlsx), PowerPoint (.pptx), PNG, JPEG"
       - Returns `{ valid: true, errors: [] }` or `{ valid: false, errors: [...] }`

    2. `uploadFileToStorage(options: UploadOptions): Promise<void>`
       - Uses tus-js-client to upload via TUS protocol
       - Endpoint: derive the project ref from `import.meta.env.VITE_SUPABASE_URL` using regex extraction — do NOT use string `.replace()` as it breaks with `api.` subdomain prefixes:
         ```typescript
         function getStorageEndpoint(): string {
           const supabaseUrl = import.meta.env.VITE_SUPABASE_URL;
           const match = /([a-z0-9]+)\.supabase\.co/.exec(supabaseUrl);
           if (!match) throw new Error('Cannot extract project ref from VITE_SUPABASE_URL');
           const projectRef = match[1];
           return `https://${projectRef}.storage.supabase.co/storage/v1/upload/resumable`;
         }
         ```
         This safely handles all URL formats: `https://xyz.supabase.co`, `https://api.xyz.supabase.co`, etc.
       - Get the user's access token from Supabase client: `import { supabase } from './supabase'` then `const { data: { session } } = await supabase.auth.getSession()` — use `session.access_token` for the Authorization header
       - TUS Upload config:
         ```
         endpoint: storageUrl,
         retryDelays: [0, 3000, 5000, 10000, 20000],
         headers: { authorization: `Bearer ${accessToken}`, 'x-upsert': 'false' },
         uploadSignature: options.token,
         metadata: {
           bucketName: options.bucketId,
           objectName: options.objectPath,
           contentType: options.file.type,
           cacheControl: '3600',
         },
         chunkSize: TUS_CHUNK_SIZE,
         onProgress(bytesUploaded, bytesTotal) {
           options.onProgress?.(Math.round((bytesUploaded / bytesTotal) * 100));
         },
         onSuccess: () => resolve(),
         onError: (err) => { options.onError?.(err); reject(err); },
         ```
       - Wrap in a Promise that resolves on onSuccess and rejects on onError
       - Call `upload.start()`

    3. `formatFileSize(bytes: number): string`
       - Returns human-readable size: "1.2 MB", "450 KB", etc.
       - Use KB for < 1 MB, MB for >= 1 MB

    4. `async refreshSignedUrl(versionId: number, mode?: 'download'): Promise<{ url: string, expiresIn: number }>`
       - Calls `GET /api/document-versions/${versionId}/pdf/download${mode === 'download' ? '?mode=download' : ''}` with `Accept: application/json` header
       - Returns the fresh `{ url, expiresIn }` response
       - This is the stub for the "auto-refresh on expiry" locked decision. Phase 4 UI components will call this when a signed URL returns 400/403 to silently obtain a new URL without user action.
       - Per user decision: "Auto-refresh on expiry — app detects expired URL and silently fetches a new signed URL"

    **Important:** This module does NOT create any React components or UI. It provides the functions that Phase 4 components will call. The progress callback (`onProgress`) is the hook for progress bar UI. The `refreshSignedUrl` function is the hook for auto-refresh on expiry — Phase 4 will wire it into the download/preview flow with retry logic on 400/403 responses.
  </action>
  <verify>
    - `tus-js-client` appears in package.json dependencies
    - `client/src/lib/storage.ts` exists and exports `uploadFileToStorage`, `validateFile`, `formatFileSize`, `refreshSignedUrl`, `ACCEPTED_FILE_EXTENSIONS`, `ACCEPTED_MIME_TYPES`, `MAX_FILE_SIZE_BYTES`
    - TypeScript compiles without errors
    - `validateFile` returns errors for files > 10 MB and unsupported MIME types
    - `uploadFileToStorage` creates a tus.Upload with correct endpoint, chunkSize, and metadata
  </verify>
  <done>
    tus-js-client installed. client/src/lib/storage.ts provides: validateFile (size + type checks with clear messages), uploadFileToStorage (TUS resumable upload with progress callback), refreshSignedUrl (auto-refresh stub for expired download URLs per locked decision), formatFileSize utility, and all relevant constants. Ready for Phase 4 UI components to consume.
  </done>
</task>

</tasks>

<verification>
- No references to `generateS3Key`, `uploadToS3`, `getLocalFilePath`, or `deleteFromS3` in active code (only in the deprecation comment in s3.ts)
- `grep -r "from.*['\"]./s3['\"]" server/` returns nothing (no imports of old module)
- All upload/download/delete operations route through storage-supabase.ts
- BU creation also creates a storage bucket
- Client can generate a TUS upload from the signed URL returned by the new endpoint
- TypeScript compiles clean: `npx tsc --noEmit`
</verification>

<success_criteria>
1. `POST /api/document-versions/:id/upload-url` endpoint returns `{signedUrl, token, path, bucketId}` after file validation
2. `POST /api/document-versions/:id/upload-confirm` endpoint records the uploaded file in the database
3. `GET /api/document-versions/:id/pdf/download` returns a signed URL (JSON or 302 redirect)
4. `DELETE /api/document-versions/:id/pdf` removes the file from Supabase Storage
5. `GET /api/document-versions/:id/pdf/to-markdown` fetches PDF from Supabase Storage for processing
6. New BU creation provisions a storage bucket
7. `client/src/lib/storage.ts` provides TUS upload with progress tracking for files of any size
8. Zero references to old S3 functions in active imports
</success_criteria>

<output>
After completion, create `.planning/phases/02-storage-migration/02-02-SUMMARY.md`
</output>
