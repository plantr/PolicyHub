---
phase: 03-vercel-deployment
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - shared/schema.ts
  - supabase/migrations/0006_ai_jobs.sql
  - server/routes.ts
  - client/src/hooks/use-ai-job.ts
autonomous: true
requirements: [FUNC-01, FUNC-02, FUNC-03]

must_haves:
  truths:
    - "AI analysis endpoints return a job ID immediately instead of blocking until the Anthropic API responds"
    - "Client can poll GET /api/ai-jobs/:jobId to see job status, progress messages, and results"
    - "AI processing runs asynchronously via fire-and-forget within the same function invocation"
    - "Job progress updates are written to the ai_jobs table during processing (e.g., 'Analyzing batch 2 of 5...')"
    - "Failed AI jobs record the error message in the ai_jobs table and set status to 'failed'"
  artifacts:
    - path: "shared/schema.ts"
      provides: "ai_jobs Drizzle table definition"
      contains: "aiJobs"
    - path: "supabase/migrations/0006_ai_jobs.sql"
      provides: "DDL for ai_jobs table with RLS enabled"
      contains: "CREATE TABLE ai_jobs"
    - path: "server/routes.ts"
      provides: "Refactored AI endpoints using dispatch-and-fire pattern + polling endpoint"
      contains: "api/ai-jobs"
    - path: "client/src/hooks/use-ai-job.ts"
      provides: "React hook for polling AI job status"
      contains: "useAiJob"
  key_links:
    - from: "server/routes.ts"
      to: "shared/schema.ts"
      via: "aiJobs table import for insert/update/select"
      pattern: "from.*aiJobs|aiJobs"
    - from: "client/src/hooks/use-ai-job.ts"
      to: "/api/ai-jobs/:jobId"
      via: "fetch polling with react-query refetchInterval"
      pattern: "api/ai-jobs"
    - from: "server/routes.ts (dispatch)"
      to: "server/routes.ts (processor)"
      via: "fire-and-forget processAi*Job call without await"
      pattern: "\\.catch\\("
---

<objective>
Implement the background job queue for AI analysis endpoints using a Supabase DB table and fire-and-forget dispatch pattern.

Purpose: The three AI endpoints (`ai-match`, `ai-coverage`, `ai-map-controls`) currently block until the Anthropic API responds, which risks Vercel function timeouts. Per the locked user decision, these must use a background job + polling pattern: the endpoint creates a job record, fires off processing asynchronously, and returns a job ID immediately. The client polls for status updates. This eliminates timeout risk and enables progress indicators.

Output: ai_jobs Drizzle schema + SQL migration, refactored AI endpoints with dispatch pattern, polling endpoint, client-side useAiJob hook
</objective>

<execution_context>
@/Users/robert.plant/.claude/get-shit-done/workflows/execute-plan.md
@/Users/robert.plant/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-vercel-deployment/03-RESEARCH.md
@server/routes.ts (lines 1169-1543 — all 3 AI endpoints)
@shared/schema.ts (for Drizzle table definition patterns)
@client/src/lib/queryClient.ts (for React Query patterns)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ai_jobs table schema and SQL migration</name>
  <files>shared/schema.ts, supabase/migrations/0006_ai_jobs.sql</files>
  <action>
1. Add the `aiJobs` Drizzle table definition to `shared/schema.ts`. Place it after the existing table definitions (near the bottom, before any export statements). Follow existing patterns in the schema file:

```typescript
export const aiJobs = pgTable("ai_jobs", {
  id: uuid("id").defaultRandom().primaryKey(),
  jobType: text("job_type").notNull(),  // 'ai-match', 'ai-coverage', 'ai-map-controls'
  entityId: integer("entity_id").notNull(),  // mappingId, requirementId, or documentId
  status: text("status").notNull().default("pending"),  // 'pending', 'processing', 'completed', 'failed'
  progressMessage: text("progress_message"),
  result: jsonb("result"),
  errorMessage: text("error_message"),
  createdAt: timestamp("created_at", { withTimezone: true }).defaultNow(),
  updatedAt: timestamp("updated_at", { withTimezone: true }).defaultNow(),
});
```

Import `uuid` and `jsonb` from `drizzle-orm/pg-core` if not already imported. Check existing imports at the top of shared/schema.ts — `uuid` may not be in use yet. The file already imports `pgTable`, `text`, `integer`, `timestamp`, etc.

Also add the insert schema:
```typescript
export const insertAiJobSchema = createInsertSchema(aiJobs);
```

2. Create `supabase/migrations/0006_ai_jobs.sql`:

```sql
-- AI background job queue for async Anthropic API processing
CREATE TABLE ai_jobs (
  id uuid DEFAULT gen_random_uuid() PRIMARY KEY,
  job_type text NOT NULL CHECK (job_type IN ('ai-match', 'ai-coverage', 'ai-map-controls')),
  entity_id integer NOT NULL,
  status text NOT NULL DEFAULT 'pending' CHECK (status IN ('pending', 'processing', 'completed', 'failed')),
  progress_message text,
  result jsonb,
  error_message text,
  created_at timestamptz DEFAULT now(),
  updated_at timestamptz DEFAULT now()
);

-- Indexes for polling and lookup
CREATE INDEX ai_jobs_status_idx ON ai_jobs(status);
CREATE INDEX ai_jobs_entity_idx ON ai_jobs(job_type, entity_id);

-- Enable RLS (consistent with all other tables)
ALTER TABLE ai_jobs ENABLE ROW LEVEL SECURITY;

-- Permissive read policy: any authenticated user can poll their own jobs
-- Jobs are short-lived operational records, not BU-scoped data
CREATE POLICY "ai_jobs_select_authenticated" ON ai_jobs
  FOR SELECT TO authenticated
  USING (true);

-- Only service role can insert/update (server-side only)
-- No INSERT/UPDATE/DELETE policies for authenticated — server uses service role
```

Note: No INSERT/UPDATE/DELETE policies for `authenticated` role — all job creation and updates happen server-side via supabaseAdmin (service role) which bypasses RLS. Only SELECT is needed for client polling.
  </action>
  <verify>
- `grep "aiJobs" shared/schema.ts` shows the table definition
- `grep "uuid" shared/schema.ts` confirms uuid import
- `cat supabase/migrations/0006_ai_jobs.sql` shows the CREATE TABLE with CHECK constraints and RLS
- `grep "insertAiJobSchema" shared/schema.ts` shows the insert schema
  </verify>
  <done>ai_jobs Drizzle table definition exists in shared/schema.ts with all required columns, SQL migration 0006 creates the table with indexes and RLS enabled, permissive read policy allows authenticated polling</done>
</task>

<task type="auto">
  <name>Task 2: Refactor AI endpoints to dispatch-and-fire pattern with polling endpoint</name>
  <files>server/routes.ts, client/src/hooks/use-ai-job.ts</files>
  <action>
**Part A — Add ai_jobs import and polling endpoint to server/routes.ts:**

1. Add `aiJobs` to the imports from `@shared/schema` at the top of routes.ts (line ~31-36).

2. Add a GET polling endpoint BEFORE the AI endpoints (around line 1165, after gap analysis and before the AI match section). This endpoint is simple:

```typescript
// === AI JOB POLLING ===
app.get("/api/ai-jobs/:jobId", async (req, res) => {
  const job = await db.select().from(schema.aiJobs)
    .where(eq(schema.aiJobs.id, req.params.jobId))
    .then(r => r[0]);
  if (!job) return res.status(404).json({ message: "Job not found" });
  res.json(job);
});
```

**Part B — Refactor the 3 AI endpoints to dispatch-and-fire pattern:**

For each of the 3 endpoints, the pattern is the same:
1. Keep all the existing validation logic (check entity exists, has content, etc.)
2. After validation passes, INSERT a new row into `ai_jobs` with status 'pending'
3. Fire off the processing function WITHOUT awaiting it (fire-and-forget with `.catch()`)
4. Return the job ID immediately to the client

**Endpoint 1: POST /api/gap-analysis/ai-match/:mappingId (line ~1169)**

Keep validation (lines 1170-1189). Then replace the Anthropic call and response with:

```typescript
// Create job record
const [job] = await db.insert(schema.aiJobs).values({
  jobType: 'ai-match',
  entityId: mappingId,
  status: 'pending',
  progressMessage: 'Queued for analysis...',
}).returning();

// Fire-and-forget — do NOT await
processAiMatchJob(job.id, mappingId).catch(err => {
  console.error('AI match job processing error:', err);
});

res.json({ jobId: job.id, status: 'pending' });
```

Extract the existing Anthropic processing logic into a standalone async function `processAiMatchJob` defined OUTSIDE the route handler (above the route registration, or after all routes but still inside `registerRoutes`). This function:
- Updates job status to 'processing' with progress message
- Runs the existing Anthropic API call (lines 1191-1251)
- On success: updates job status to 'completed', stores result as JSON, updates the requirement mapping (lines 1253-1255)
- On failure: updates job status to 'failed' with error message
- Always updates `updated_at` to `new Date()`

```typescript
async function processAiMatchJob(jobId: string, mappingId: number) {
  try {
    await db.update(schema.aiJobs).set({
      status: 'processing',
      progressMessage: 'Analyzing requirement-document match...',
      updatedAt: new Date(),
    }).where(eq(schema.aiJobs.id, jobId));

    // ... existing validation + Anthropic call logic (lines 1172-1255) ...
    // Move the mapping lookup, requirement lookup, document lookup, Anthropic call, and DB update here

    await db.update(schema.aiJobs).set({
      status: 'completed',
      result: { aiMatchScore: aiScore, aiMatchRationale: aiRationale, aiMatchRecommendations: aiRecommendations },
      progressMessage: 'Analysis complete',
      updatedAt: new Date(),
    }).where(eq(schema.aiJobs.id, jobId));
  } catch (err: any) {
    await db.update(schema.aiJobs).set({
      status: 'failed',
      errorMessage: err.message || 'AI match analysis failed',
      updatedAt: new Date(),
    }).where(eq(schema.aiJobs.id, jobId));
  }
}
```

**Endpoint 2: POST /api/requirements/:id/ai-coverage (line ~1265)**

Same pattern. Extract to `processAiCoverageJob(jobId, requirementId)`. Keep route validation. Fire-and-forget.

**Endpoint 3: POST /api/documents/:id/ai-map-controls (line ~1378)**

Same pattern. Extract to `processAiMapControlsJob(jobId, documentId)`. Keep route validation. Fire-and-forget.

For `ai-map-controls`, add progress updates PER BATCH within the for loop:
```typescript
for (let i = 0; i < batches.length; i++) {
  await db.update(schema.aiJobs).set({
    progressMessage: `Analyzing batch ${i + 1} of ${batches.length}...`,
    updatedAt: new Date(),
  }).where(eq(schema.aiJobs.id, jobId));

  // ... existing batch processing ...
}
```

This satisfies the user decision: "User sees progress indicator with status updates while waiting (e.g., 'Analyzing page 3 of 12...')"

**Part C — Create client-side polling hook:**

Create `client/src/hooks/use-ai-job.ts`:

```typescript
import { useQuery } from "@tanstack/react-query";

interface AiJob {
  id: string;
  jobType: string;
  entityId: number;
  status: "pending" | "processing" | "completed" | "failed";
  progressMessage: string | null;
  result: Record<string, any> | null;
  errorMessage: string | null;
  createdAt: string;
  updatedAt: string;
}

export function useAiJob(jobId: string | null) {
  return useQuery<AiJob>({
    queryKey: ["/api/ai-jobs", jobId],
    queryFn: async () => {
      const res = await fetch(`/api/ai-jobs/${jobId}`);
      if (!res.ok) throw new Error("Failed to fetch job status");
      return res.json();
    },
    enabled: !!jobId,
    refetchInterval: (query) => {
      const status = query.state.data?.status;
      if (status === "completed" || status === "failed") return false;
      return 2000; // Poll every 2 seconds while pending/processing
    },
  });
}
```

This hook:
- Only enables when jobId is non-null
- Polls every 2 seconds while status is 'pending' or 'processing'
- Stops polling when status reaches 'completed' or 'failed'
- Returns the full job object including progressMessage for UI display

**IMPORTANT:** Do NOT modify any client-side components that call the AI endpoints yet — that is Phase 4 work. This hook is the utility; wiring it into existing mutation calls happens when the client is migrated. The server-side endpoints still return the same job dispatch response shape ({ jobId, status }) which existing client code will need to adapt to in Phase 4.
  </action>
  <verify>
- `grep "api/ai-jobs" server/routes.ts` shows the polling endpoint
- `grep "processAiMatchJob" server/routes.ts` shows the extracted processor function
- `grep "processAiCoverageJob" server/routes.ts` shows the extracted processor function
- `grep "processAiMapControlsJob" server/routes.ts` shows the extracted processor function
- `grep "fire-and-forget\|\.catch(" server/routes.ts` shows the fire-and-forget pattern
- `grep "Analyzing batch" server/routes.ts` shows progress updates in ai-map-controls
- `cat client/src/hooks/use-ai-job.ts` shows the polling hook with refetchInterval
- `grep "jobId" server/routes.ts | head -3` shows job ID returned in responses
  </verify>
  <done>All 3 AI endpoints dispatch jobs to ai_jobs table and fire-and-forget async processing, polling endpoint GET /api/ai-jobs/:jobId returns job status and progress, useAiJob React hook polls every 2s until completion, ai-map-controls reports per-batch progress messages</done>
</task>

</tasks>

<verification>
1. `shared/schema.ts` contains the `aiJobs` table definition with all columns
2. `supabase/migrations/0006_ai_jobs.sql` creates the table with constraints and RLS
3. All 3 AI endpoints in `server/routes.ts` create a job record and return immediately
4. Processing functions are fire-and-forget (no `await` before the process call)
5. `GET /api/ai-jobs/:jobId` polling endpoint exists
6. `client/src/hooks/use-ai-job.ts` exports `useAiJob` with polling
7. TypeScript compiles without new errors: `npx tsc --noEmit`
</verification>

<success_criteria>
AI analysis endpoints immediately return a job ID without waiting for Anthropic API responses. Background processing updates job status and progress in the ai_jobs table. The client-side useAiJob hook polls for updates every 2 seconds and stops when the job completes or fails.
</success_criteria>

<output>
After completion, create `.planning/phases/03-vercel-deployment/03-02-SUMMARY.md`
</output>
